
### What is Autoscaling?

**Simple Explanation:**
Autoscaling automatically adjusts resources (Pods, CPU, memory, or nodes) based on current demand. It's like having a smart system that adds more servers when traffic increases and removes them when traffic decreases.

**Why We Need Autoscaling:**
- **Variable Workloads:** Traffic and resource needs change over time
- **Cost Optimization:** Pay only for what you use
- **Performance:** Ensure applications have enough resources
- **Efficiency:** Automatically handle scaling decisions

**Types of Autoscaling in Kubernetes:**
1. **HPA (Horizontal Pod Autoscaler)** - Scales number of Pods
2. **VPA (Vertical Pod Autoscaler)** - Adjusts CPU/memory requests/limits
3. **KEDA (Kubernetes Event-Driven Autoscaling)** - Event-driven scaling
4. **Cluster Autoscaler** - Scales cluster nodes (traditional)
5. **Karpenter** - High-performance node autoscaler (modern alternative)

### Autoscaling Overview Diagram

```mermaid
graph TB
    subgraph "Autoscaling Types"
        HPA[HPA<br/>Horizontal Pod Autoscaler<br/>Scales Pods]
        VPA[VPA<br/>Vertical Pod Autoscaler<br/>Adjusts Resources]
        KEDA[KEDA<br/>Event-Driven Autoscaling<br/>Event-Based Scaling]
        CA[Cluster Autoscaler<br/>Scales Nodes]
        Karpenter[Karpenter<br/>High-Performance<br/>Node Autoscaler]
    end
    
    subgraph "Metrics Sources"
        Metrics[Metrics Server<br/>CPU/Memory Metrics]
        Prometheus[Prometheus<br/>Custom Metrics]
        Events[Event Sources<br/>Queue/Kafka/etc]
    end
    
    subgraph "Targets"
        Pods[Pods<br/>Application Instances]
        Resources[Resources<br/>CPU/Memory]
        Nodes[Nodes<br/>Cluster Nodes]
    end
    
    HPA --> Metrics
    HPA --> Prometheus
    HPA --> Pods
    
    VPA --> Metrics
    VPA --> Resources
    
    KEDA --> Events
    KEDA --> Pods
    
    CA --> Nodes
    Karpenter --> Nodes
    
    style HPA fill:#326ce5,color:#fff
    style VPA fill:#326ce5,color:#fff
    style KEDA fill:#326ce5,color:#fff
    style CA fill:#326ce5,color:#fff
    style Karpenter fill:#326ce5,color:#fff
```

### When to Use Which Autoscaler?

| Autoscaler | Use Case | What It Scales | Best For |
|------------|----------|----------------|----------|
| **HPA** | CPU/Memory/ custom metrics high | Number of Pods | Stateless applications, web services |
| **VPA** | Resource requests need adjustment | CPU/Memory requests/limits | Applications with varying resource needs |
| **KEDA** | Event-driven workloads | Number of Pods based on events | Queue workers, event processors |
| **Cluster Autoscaler** | Cluster needs more nodes | Number of nodes | When Pods can't be scheduled (traditional) |
| **Karpenter** | Fast, efficient node provisioning | Number of nodes | AWS EKS, fast scaling, cost optimization |

### Key Takeaways

1. **Autoscaling optimizes resources** - Automatically adjusts to demand
2. **Multiple autoscalers available** - Choose based on your needs
3. **HPA for horizontal scaling** - Most common for Pod scaling
4. **VPA for resource optimization** - Adjusts CPU/memory per Pod
5. **KEDA for event-driven scaling** - Based on external events
6. **Cluster Autoscaler for infrastructure** - Traditional node autoscaler
7. **Karpenter for modern infrastructure** - Fast, efficient node autoscaler
8. **Can use multiple together** - Combine for comprehensive scaling

---

## HPA - Horizontal Pod Autoscaler

**Horizontal Pod Autoscaler (HPA)** automatically scales the number of Pod replicas based on observed CPU utilization, memory usage, or custom metrics.

### What is HPA?

**Simple Explanation:**
HPA automatically adds or removes Pod replicas based on metrics like CPU or memory usage. If your application is using too much CPU, HPA creates more Pods to share the load. If usage is low, it removes Pods to save resources.

**Simple Analogy:**
Think of HPA as an **automatic staffing manager**:
- Monitors how busy workers (Pods) are
- Hires more workers when busy (high CPU/memory)
- Lets workers go when not busy (low CPU/memory)
- Ensures optimal staffing levels

### Why Do We Need HPA?

**The Problem:**
- Traffic varies throughout the day
- Manual scaling is time-consuming
- Over-provisioning wastes resources
- Under-provisioning causes poor performance

**The Solution:**
- HPA automatically adjusts Pod count
- Responds to traffic changes in real-time
- Optimizes resource usage
- Maintains performance under load

### How HPA Works

**HPA Workflow:**
```
1. HPA collects metrics (CPU, memory, custom)
   ‚Üì
2. Compares current metrics to target
   ‚Üì
3. Calculates desired replica count
   ‚Üì
4. Updates Deployment/ReplicaSet
   ‚Üì
5. Controller creates/deletes Pods
   ‚Üì
6. Repeats every 15 seconds (default)
```

**Scaling Decision:**
```
desiredReplicas = ceil[currentReplicas * (currentMetricValue / desiredMetricValue)]
```

**Example:**
```
Current: 2 Pods, CPU: 80%, Target: 50%
Desired: ceil[2 * (80/50)] = ceil[3.2] = 4 Pods
Result: Scale up to 4 Pods
```

### HPA Architecture Diagram

```mermaid
graph TB
    MS[Metrics Server<br/>CPU Memory Metrics]
    PM[Prometheus<br/>Custom Metrics]
    HPA[HPA Controller<br/>Horizontal Pod Autoscaler]
    DEP[Deployment<br/>nginx-deployment]
    RS[ReplicaSet]
    PODS[Pods<br/>Application Containers]
    
    MS --> HPA
    PM --> HPA
    HPA --> DEP
    DEP --> RS
    RS --> PODS
    
    style HPA fill:#326ce5,color:#fff
    style DEP fill:#00d4aa,color:#fff
    style PODS fill:#f4a261,color:#000
```

### HPA YAML Structure

**Basic HPA Structure:**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: <hpa-name>
  namespace: <namespace>
spec:
  scaleTargetRef:        # What to scale
    apiVersion: apps/v1
    kind: Deployment
    name: <deployment-name>
  minReplicas: <number>   # Minimum Pods
  maxReplicas: <number>   # Maximum Pods
  metrics:                # Metrics to track
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: <percentage>
```

**Key Fields Explained:**

**1. scaleTargetRef:**
- **apiVersion:** API version of target resource
- **kind:** Type of resource (Deployment, ReplicaSet, StatefulSet)
- **name:** Name of the resource to scale

**2. minReplicas:**
- Minimum number of Pod replicas
- HPA will never scale below this
- Default: 1

**3. maxReplicas:**
- Maximum number of Pod replicas
- HPA will never scale above this
- Required field

**4. metrics:**
- List of metrics to track
- Can track multiple metrics
- Types: Resource, Pods, Object, External

**5. behavior (optional):**
- Controls scaling behavior
- Scale up/down policies
- Stabilization windows

### HPA Metrics Types

**1. Resource Metrics:**
- CPU utilization
- Memory utilization
- Requires Metrics Server

**2. Pod Metrics:**
- Average metric value across all Pods
- Custom metrics per Pod

**3. Object Metrics:**
- Metrics from another object
- Example: Ingress requests per second

**4. External Metrics:**
- Metrics from outside Kubernetes
- Example: Queue length

### Creating HPA

**Example: HPA for CPU and Memory**

> **üìÅ Reference:** See example YAML file: [`apache/hpa.yaml`](https://github.com/jayeshjd555/Kubernetes/blob/main/apache/hpa.yaml)

**üìö Tutorial:**
- **[Autoscaling Tutorial](https://github.com/jayeshjd555/Kubernetes/blob/main/tutorials/07-autoscaling/README.md)** - Step-by-step tutorial to set up and test HPA

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: apache-hpa
  namespace: apache
spec:
  scaleTargetRef:
    kind: Deployment
    name: apache-deployment
    apiVersion: apps/v1
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
```

**Commands:**
```bash
# Create HPA
kubectl apply -f apache/hpa.yaml

# View HPA
kubectl get hpa -n apache

# Describe HPA
kubectl describe hpa apache-hpa -n apache

# Watch HPA in real-time
kubectl get hpa -n apache -w
```

### HPA Behavior Configuration

**Scale Up/Down Policies:**
```yaml
spec:
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
```

**Behavior Options:**
- **stabilizationWindowSeconds:** Wait time before scaling
- **policies:** Scaling rules (Percent or Pods)
- **selectPolicy:** Min, Max, or Disabled

### HPA Best Practices

**1. Set Appropriate Limits:**
- Set minReplicas based on minimum load
- Set maxReplicas based on maximum expected load
- Consider cost implications

**2. Configure Resource Requests:**
- HPA needs resource requests to calculate utilization
- Without requests, HPA can't determine CPU/memory usage

**3. Use Multiple Metrics:**
- Combine CPU and memory metrics
- Add custom metrics for better scaling decisions

**4. Configure Behavior:**
- Set appropriate stabilization windows
- Prevent rapid scaling up/down
- Use policies to control scaling speed

**5. Monitor HPA:**
- Watch HPA decisions
- Check metrics availability
- Monitor scaling events

**6. Test Scaling:**
- Test scale-up scenarios
- Test scale-down scenarios
- Verify metrics collection

### HPA Troubleshooting

**HPA Not Scaling:**
```bash
# Check HPA status
kubectl describe hpa <hpa-name> -n <namespace>

# Check metrics availability
kubectl top pods -n <namespace>

# Check Metrics Server
kubectl get deployment metrics-server -n kube-system
```

**Common Issues:**
1. **Metrics not available:**
   - Install Metrics Server
   - Check Metrics Server logs

2. **HPA shows "unknown":**
   - Metrics Server not running
   - Resource requests not set

3. **Not scaling as expected:**
   - Check target utilization
   - Verify metrics are being collected
   - Check min/max replicas

### Key Takeaways

1. **HPA scales Pods horizontally** - Adds/removes Pod replicas
2. **Based on metrics** - CPU, memory, or custom metrics
3. **Requires Metrics Server** - For resource metrics
4. **Works with Deployments** - And ReplicaSets, StatefulSets
5. **Configurable behavior** - Control scaling speed and policies
6. **Set resource requests** - Required for resource-based scaling
7. **Monitor and test** - Ensure HPA works as expected

---

## VPA - Vertical Pod Autoscaler

**Vertical Pod Autoscaler (VPA)** automatically adjusts CPU and memory requests and limits for Pods based on historical usage. Unlike HPA which scales horizontally, VPA scales vertically by adjusting resource allocations.

### What is VPA?

**Simple Explanation:**
VPA automatically adjusts the CPU and memory requests and limits for your Pods based on how much they actually use. If a Pod consistently uses more CPU than requested, VPA increases the request. If it uses less, VPA decreases it.

**Simple Analogy:**
Think of VPA as a **smart resource allocator**:
- Monitors how much resources Pods actually use
- Adjusts resource allocations (CPU/memory) per Pod
- Optimizes resource requests and limits
- Like adjusting a worker's desk size based on their needs

**Key Difference from HPA:**
- **HPA:** Changes number of Pods (horizontal scaling)
- **VPA:** Changes resources per Pod (vertical scaling)

### Why Do We Need VPA?

**The Problem:**
- Hard to predict resource needs
- Over-provisioning wastes resources
- Under-provisioning causes OOM kills
- Manual adjustment is time-consuming

**The Solution:**
- VPA analyzes historical usage
- Automatically adjusts requests/limits
- Prevents OOM kills
- Optimizes resource allocation

### How VPA Works

**VPA Components:**
1. **Recommender:** Analyzes usage and recommends values
2. **Updater:** Updates running Pods (in Auto mode)
3. **Admission Controller:** Sets requests/limits for new Pods

**VPA Workflow:**
```
1. VPA Recommender analyzes Pod resource usage
   ‚Üì
2. Generates recommendations for requests/limits
   ‚Üì
3. VPA Updater (Auto mode) evicts Pods with new values
   ‚Üì
4. VPA Admission Controller sets values for new Pods
   ‚Üì
5. Pods restart with optimized resources
```

**VPA Modes:**
- **Off:** Only provides recommendations
- **Initial:** Sets resources only when Pods are created
- **Auto:** Automatically updates running Pods (evicts and recreates)
- **Recreate:** Similar to Auto but waits for Pod termination

### VPA Architecture Diagram

```mermaid
graph TB
    HIST[Historical Metrics<br/>CPU Memory Usage]
    REC[Recommender<br/>Analyzes Usage]
    VPACtrl[VPA Controller<br/>Vertical Pod Autoscaler]
    UPD[Updater<br/>Updates Pods]
    AC[Admission Controller<br/>Sets Resources]
    POD1[Pod 1<br/>Current Resources]
    POD2[Pod 2<br/>Current Resources]
    POD3[Pod 3<br/>Recommended Resources]
    
    HIST --> REC
    REC --> VPACtrl
    VPACtrl --> UPD
    VPACtrl --> AC
    UPD --> POD1
    UPD --> POD2
    AC --> POD3
    
    style VPACtrl fill:#326ce5,color:#fff
    style REC fill:#00d4aa,color:#fff
    style POD3 fill:#f4a261,color:#000
```

### VPA YAML Structure

**Basic VPA Structure:**
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: <vpa-name>
  namespace: <namespace>
spec:
  targetRef:              # What to scale
    apiVersion: apps/v1
    kind: Deployment
    name: <deployment-name>
  updatePolicy:           # How to update
    updateMode: <mode>    # Off, Initial, Auto, Recreate
  resourcePolicy:         # Resource constraints (optional)
    containerPolicies:
    - containerName: <container-name>
      minAllowed:
        cpu: <amount>
        memory: <amount>
      maxAllowed:
        cpu: <amount>
        memory: <amount>
```

**Key Fields Explained:**

**1. targetRef:**
- **apiVersion:** API version of target resource
- **kind:** Type of resource (Deployment, ReplicaSet, StatefulSet)
- **name:** Name of the resource to scale

**2. updatePolicy:**
- **updateMode:** How VPA updates Pods
  - **Off:** Only recommendations, no updates
  - **Initial:** Set resources only at Pod creation
  - **Auto:** Automatically update running Pods
  - **Recreate:** Update by recreating Pods

**3. resourcePolicy (optional):**
- **containerPolicies:** Per-container resource constraints
- **minAllowed:** Minimum CPU/memory
- **maxAllowed:** Maximum CPU/memory

### Creating VPA

**Example: VPA with Auto Mode**

> **üìÅ Reference:** See example YAML file: [`apache/vpa.yaml`](https://github.com/jayeshjd555/Kubernetes/blob/main/apache/vpa.yaml)

```yaml
kind: VerticalPodAutoscaler
apiVersion: autoscaling.k8s.io/v1
metadata:
  name: apache-vpa
  namespace: apache
spec:
  targetRef:
    name: apache-deployment
    apiVersion: apps/v1
    kind: Deployment
  updatePolicy:
    updateMode: "Auto"
```

**Example: VPA with Resource Constraints**
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: apache-vpa
  namespace: apache
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: apache-deployment
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: apache
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 4Gi
```

**Commands:**
```bash
# Install VPA (if not installed)
# Follow VPA installation guide for your cluster

# Create VPA
kubectl apply -f apache/vpa.yaml

# View VPA
kubectl get vpa -n apache

# Describe VPA (see recommendations)
kubectl describe vpa apache-vpa -n apache

# View VPA recommendations
kubectl get vpa apache-vpa -n apache -o yaml
```

### VPA Update Modes Explained

**1. Off Mode:**
- VPA only provides recommendations
- No automatic updates
- Use for analysis and planning

**2. Initial Mode:**
- Sets resources only when Pods are created
- Doesn't update running Pods
- Safe for production

**3. Auto Mode:**
- Automatically updates running Pods
- Evicts Pods and recreates with new resources
- Most aggressive, use carefully

**4. Recreate Mode:**
- Similar to Auto but waits for Pod termination
- More controlled than Auto
- Good for stateful workloads

### VPA Best Practices

**1. Start with Off Mode:**
- Analyze recommendations first
- Understand resource needs
- Plan resource allocation

**2. Use Initial Mode for Production:**
- Safer than Auto mode
- Sets resources for new Pods
- No disruption to running Pods

**3. Set Resource Constraints:**
- Use minAllowed to prevent under-provisioning
- Use maxAllowed to prevent over-provisioning
- Protects against extreme recommendations

**4. Monitor VPA Recommendations:**
- Review recommendations regularly
- Adjust constraints based on observations
- Verify recommendations make sense

**5. Don't Use with HPA (CPU/Memory):**
- VPA and HPA can conflict
- Use VPA for resource optimization
- Use HPA for scaling Pod count

**6. Test in Non-Production:**
- Test VPA behavior first
- Understand update impact
- Verify resource adjustments

### VPA Limitations

**1. Pod Disruption:**
- Auto/Recreate modes evict Pods
- Causes temporary unavailability
- Not suitable for all workloads

**2. Stateful Workloads:**
- VPA can disrupt stateful applications
- Use carefully with StatefulSets
- Consider Initial mode only

**3. HPA Conflicts:**
- Don't use VPA with HPA on same metrics
- Can cause scaling conflicts
- Use VPA for optimization, HPA for scaling

**4. Requires VPA Installation:**
- Not included in standard Kubernetes
- Need to install VPA components
- Additional maintenance overhead

### Key Takeaways

1. **VPA adjusts resources vertically** - Changes CPU/memory per Pod
2. **Based on historical usage** - Analyzes past resource consumption
3. **Multiple update modes** - Off, Initial, Auto, Recreate
4. **Can set constraints** - Min/max allowed resources
5. **Don't use with HPA** - Can cause conflicts
6. **Causes Pod disruption** - In Auto/Recreate modes
7. **Requires VPA installation** - Not standard Kubernetes

---

## KEDA - Kubernetes Event-Driven Autoscaling

**KEDA (Kubernetes Event-Driven Autoscaling)** is a Kubernetes-based event-driven autoscaling component that can scale workloads based on events from various sources like message queues, databases, and cloud services.

### What is KEDA?

**Simple Explanation:**
KEDA automatically scales Pods based on events from external systems like message queues, databases, or cloud services. If there are many messages in a queue, KEDA scales up Pods to process them. When the queue is empty, it scales down.

**Simple Analogy:**
Think of KEDA as an **event-driven staffing manager**:
- Monitors external events (queue length, database connections, etc.)
- Scales workers (Pods) based on event volume
- Responds to real-time event changes
- Like hiring workers when orders come in

**Key Difference:**
- **HPA:** Scales based on CPU/memory metrics
- **KEDA:** Scales based on external events

### Why Do We Need KEDA?

**The Problem:**
- Event-driven workloads need event-based scaling
- CPU/memory metrics don't reflect event volume
- Need to scale based on queue length, message count, etc.
- HPA can't access external event sources

**The Solution:**
- KEDA connects to event sources
- Scales based on event metrics
- Supports many event sources
- Provides event-driven autoscaling

### How KEDA Works

**KEDA Components:**
1. **ScaledObject:** Defines what to scale and how
2. **Scalers:** Connect to event sources (queues, databases, etc.)
3. **Metrics Adapter:** Exposes metrics to HPA
4. **Controller:** Manages scaling decisions

**KEDA Workflow:**
```
1. KEDA Scaler connects to event source (e.g., RabbitMQ)
   ‚Üì
2. Monitors event metrics (e.g., queue length)
   ‚Üì
3. KEDA Metrics Adapter exposes metrics to HPA
   ‚Üì
4. HPA scales Pods based on metrics
   ‚Üì
5. Pods process events
   ‚Üì
6. KEDA scales down when events decrease
```

### KEDA Architecture Diagram

```mermaid
graph TB
    QUEUE[Message Queue<br/>RabbitMQ Kafka]
    DB[Database<br/>PostgreSQL MySQL]
    CLOUD[Cloud Services<br/>AWS SQS Azure Queue]
    SCALER[Scalers<br/>Event Source Connectors]
    SO[ScaledObject<br/>Scaling Definition]
    KEDACtrl[KEDA Controller<br/>Manages Scaling]
    MA[Metrics Adapter<br/>Exposes Metrics]
    HPA[HPA<br/>Horizontal Pod Autoscaler]
    DEP[Deployment<br/>Worker Pods]
    PODS[Pods<br/>Application Containers]
    
    QUEUE --> SCALER
    DB --> SCALER
    CLOUD --> SCALER
    SO --> KEDACtrl
    KEDACtrl --> SCALER
    SCALER --> MA
    MA --> HPA
    HPA --> DEP
    DEP --> PODS
    
    style KEDACtrl fill:#326ce5,color:#fff
    style HPA fill:#00d4aa,color:#fff
    style PODS fill:#f4a261,color:#000
```

### KEDA ScaledObject YAML Structure

**Basic ScaledObject Structure:**
```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: <scaled-object-name>
  namespace: <namespace>
spec:
  scaleTargetRef:        # What to scale
    name: <deployment-name>
  minReplicaCount: <number>
  maxReplicaCount: <number>
  triggers:              # Event sources
    - type: <scaler-type>
      metadata:
        # Scaler-specific configuration
```

**Key Fields Explained:**

**1. scaleTargetRef:**
- **name:** Name of Deployment to scale
- Can also reference other workload types

**2. minReplicaCount:**
- Minimum number of Pod replicas
- Default: 0 (scale to zero)

**3. maxReplicaCount:**
- Maximum number of Pod replicas
- Required field

**4. triggers:**
- List of event sources
- Each trigger defines a scaler type and configuration
- Can have multiple triggers

### KEDA Supported Scalers

**Message Queues:**
- RabbitMQ
- Apache Kafka
- AWS SQS
- Azure Service Bus
- Redis Streams
- NATS Streaming

**Databases:**
- PostgreSQL
- MySQL
- MongoDB
- InfluxDB

**Cloud Services:**
- AWS Kinesis
- Azure Event Hubs
- GCP Pub/Sub

**Others:**
- Prometheus
- Cron
- External (custom)

### Creating KEDA ScaledObject

**Example: RabbitMQ Scaler**
```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: rabbitmq-scaledobject
  namespace: default
spec:
  scaleTargetRef:
    name: worker-deployment
  minReplicaCount: 0
  maxReplicaCount: 10
  triggers:
    - type: rabbitmq
      metadata:
        queueName: tasks
        queueLength: '5'
        host: amqp://guest:password@rabbitmq.default.svc.cluster.local:5672/
```

**Example: Kafka Scaler**
```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: kafka-scaledobject
  namespace: default
spec:
  scaleTargetRef:
    name: kafka-consumer
  minReplicaCount: 1
  maxReplicaCount: 20
  triggers:
    - type: kafka
      metadata:
        bootstrapServers: kafka:9092
        consumerGroup: my-group
        topic: events
        lagThreshold: '10'
```

**Example: Cron Scaler (Scheduled Scaling)**
```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: cron-scaledobject
  namespace: default
spec:
  scaleTargetRef:
    name: batch-job
  minReplicaCount: 0
  maxReplicaCount: 5
  triggers:
    - type: cron
      metadata:
        timezone: Etc/UTC
        start: "0 9 * * *"    # 9 AM daily
        end: "0 17 * * *"      # 5 PM daily
        desiredReplicas: "3"
```

**Commands:**
```bash
# Install KEDA (if not installed)
# Follow KEDA installation guide

# Create ScaledObject
kubectl apply -f scaledobject.yaml

# View ScaledObjects
kubectl get scaledobject

# Describe ScaledObject
kubectl describe scaledobject <name>

# View HPA created by KEDA
kubectl get hpa
```

### KEDA Best Practices

**1. Set Appropriate Replica Counts:**
- Use minReplicaCount: 0 for scale-to-zero
- Set maxReplicaCount based on capacity
- Consider cost implications

**2. Configure Lag Thresholds:**
- Set appropriate lag thresholds for queues
- Balance between responsiveness and cost
- Monitor scaling behavior

**3. Use Multiple Triggers:**
- Combine multiple event sources
- Scale based on multiple conditions
- Use trigger selection logic

**4. Monitor Scaling:**
- Watch ScaledObject status
- Monitor HPA created by KEDA
- Check event source metrics

**5. Test Scaling:**
- Test scale-up scenarios
- Test scale-down scenarios
- Verify event source connectivity

**6. Handle Scale-to-Zero:**
- Ensure applications handle cold starts
- Consider startup time
- Use appropriate minReplicaCount

### KEDA vs HPA

| Feature | KEDA | HPA |
|---------|------|-----|
| **Scaling Based On** | External events | CPU/Memory metrics |
| **Event Sources** | Many (queues, DBs, cloud) | Limited (metrics) |
| **Scale to Zero** | Yes (default) | No (min: 1) |
| **Complexity** | Higher (needs scalers) | Lower (built-in) |
| **Use Case** | Event-driven workloads | Resource-based scaling |

### Key Takeaways

1. **KEDA scales based on events** - External event sources
2. **Many supported scalers** - Queues, databases, cloud services
3. **Scale to zero** - Can scale down to 0 Pods
4. **Works with HPA** - Uses HPA under the hood
5. **Event-driven workloads** - Perfect for queue workers, processors
6. **Requires KEDA installation** - Not standard Kubernetes
7. **Flexible configuration** - Multiple triggers and scalers

---

## Cluster Autoscaler

**Cluster Autoscaler** automatically adjusts the size of the Kubernetes cluster by adding or removing nodes based on resource demands. It ensures there are enough nodes to schedule Pods while removing unused nodes to save costs.

### What is Cluster Autoscaler?

**Simple Explanation:**
Cluster Autoscaler automatically adds nodes to your cluster when Pods can't be scheduled (due to insufficient resources) and removes nodes when they're underutilized. It's like automatically adding or removing servers based on demand.

**Simple Analogy:**
Think of Cluster Autoscaler as an **automatic infrastructure manager**:
- Monitors if Pods can be scheduled
- Adds more servers (nodes) when needed
- Removes unused servers to save money
- Like automatically expanding or shrinking a parking lot

**Key Difference:**
- **HPA/VPA:** Scale Pods within existing nodes
- **Cluster Autoscaler:** Scale the cluster itself (add/remove nodes)

### Why Do We Need Cluster Autoscaler?

**The Problem:**
- Pods can't be scheduled if nodes are full
- Manual node management is time-consuming
- Over-provisioning wastes money
- Under-provisioning causes scheduling failures

**The Solution:**
- Cluster Autoscaler adds nodes automatically
- Removes unused nodes to save costs
- Responds to scheduling demands
- Optimizes cluster size

### How Cluster Autoscaler Works

**Cluster Autoscaler Workflow:**
```
1. Pod can't be scheduled (pending)
   ‚Üì
2. Cluster Autoscaler detects pending Pod
   ‚Üì
3. Calculates if adding node would help
   ‚Üì
4. Adds new node to cluster
   ‚Üì
5. Pod gets scheduled on new node
   ‚Üì
6. Monitors node utilization
   ‚Üì
7. Removes underutilized nodes
```

**Scale Up Conditions:**
- Pods are pending (can't be scheduled)
- Adding a node would allow scheduling
- Node group has capacity

**Scale Down Conditions:**
- Node utilization is below threshold
- All Pods can be moved to other nodes
- Node is not needed for cluster stability

### Cluster Autoscaler Architecture Diagram

```mermaid
graph TB
    SCHED[Scheduler<br/>Pod Scheduling]
    PENDING[Pending Pods<br/>Cant Schedule]
    MON[Monitor<br/>Cluster State]
    CA[CA Controller<br/>Cluster Autoscaler]
    DEC[Decision Engine<br/>Scale Up Down]
    NG[Node Group<br/>Auto Scaling Group]
    NEW[New Node<br/>Added]
    OLD[Old Node<br/>Removed]
    NODE1[Node 1<br/>High Utilization]
    NODE2[Node 2<br/>Low Utilization]
    
    PENDING --> CA
    SCHED --> MON
    MON --> CA
    CA --> DEC
    DEC --> NG
    NG --> NEW
    DEC --> OLD
    NEW --> NODE1
    OLD --> NODE2
    
    style CA fill:#326ce5,color:#fff
    style NG fill:#00d4aa,color:#fff
    style NEW fill:#f4a261,color:#000
```

### Cluster Autoscaler Configuration

**Deployment YAML (Example for AWS):**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      serviceAccountName: cluster-autoscaler
      containers:
      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.27.0
        name: cluster-autoscaler
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 300Mi
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/<cluster-name>
        - --balance-similar-node-groups
        - --scale-down-enabled=true
        - --scale-down-delay-after-add=10m
        - --scale-down-unneeded-time=10m
        - --scale-down-utilization-threshold=0.5
```

**Key Configuration Flags:**

**1. Cloud Provider:**
- `--cloud-provider=aws` (AWS)
- `--cloud-provider=gce` (GCP)
- `--cloud-provider=azure` (Azure)

**2. Node Group Discovery:**
- `--node-group-auto-discovery` - Auto-discover node groups
- Or specify node groups manually

**3. Scaling Behavior:**
- `--scale-down-enabled` - Enable scale down
- `--scale-down-delay-after-add` - Wait time after scale up
- `--scale-down-unneeded-time` - Time before removing node
- `--scale-down-utilization-threshold` - Utilization threshold

**4. Expander:**
- `--expander=least-waste` - Minimize waste
- `--expander=most-pods` - Maximize Pods
- `--expander=priority` - Use priority

### Cluster Autoscaler Requirements

**1. Cloud Provider Support:**
- AWS (EKS)
- GCP (GKE)
- Azure (AKS)
- On-premises (limited support)

**2. Node Groups:**
- Auto Scaling Groups (AWS)
- Instance Groups (GCP)
- VM Scale Sets (Azure)

**3. Permissions:**
- IAM roles with node management permissions
- Service account with proper roles

**4. Pod Disruption Budgets:**
- Set PDBs to control scale down
- Prevents removing nodes with critical Pods

### Cluster Autoscaler Best Practices

**1. Set Appropriate Thresholds:**
- Configure scale-down utilization threshold
- Balance between cost and availability
- Consider node startup time

**2. Use Pod Disruption Budgets:**
- Set PDBs for important workloads
- Prevents unwanted scale down
- Ensures availability

**3. Configure Scale Down Delays:**
- Set appropriate delays after scale up
- Prevents rapid scale up/down cycles
- Allows Pods to stabilize

**4. Label Node Groups:**
- Properly label node groups
- Enable auto-discovery
- Organize by workload type

**5. Monitor Cluster Autoscaler:**
- Watch autoscaler logs
- Monitor node additions/removals
- Check for scaling events

**6. Test Scaling:**
- Test scale-up scenarios
- Test scale-down scenarios
- Verify node group configuration

### Cluster Autoscaler Limitations

**1. Cloud Provider Required:**
- Needs cloud provider integration
- Limited on-premises support
- Requires proper IAM roles

**2. Node Startup Time:**
- Nodes take time to join cluster
- May cause temporary scheduling delays
- Consider in capacity planning

**3. Scale Down Constraints:**
- Can't remove nodes with local storage Pods
- Respects Pod Disruption Budgets
- May not scale down if Pods can't be moved

**4. Cost Considerations:**
- Adding nodes increases costs
- Monitor cluster size
- Set appropriate limits

### Key Takeaways

1. **Cluster Autoscaler scales nodes** - Adds/removes cluster nodes
2. **Cloud provider required** - Needs cloud integration
3. **Responds to scheduling** - Adds nodes when Pods pending
4. **Removes unused nodes** - Saves costs
5. **Respects PDBs** - Won't violate Pod Disruption Budgets
6. **Configurable thresholds** - Control scale up/down behavior
7. **Monitor and test** - Ensure proper configuration

---

## Karpenter

**Karpenter** is a high-performance, open-source cluster autoscaler for Kubernetes. It provides faster, more efficient node provisioning compared to Cluster Autoscaler by provisioning exactly the right compute resources for each workload.

### What is Karpenter?

**Simple Explanation:**
Karpenter automatically provisions the right nodes for your workloads. Unlike Cluster Autoscaler which works with node groups, Karpenter can provision any node type that matches your workload requirements, leading to better resource utilization and faster scaling.

**Simple Analogy:**
Think of Karpenter as a **smart, flexible infrastructure manager**:
- Cluster Autoscaler = Fixed parking lot sizes (node groups)
- Karpenter = Dynamic parking spaces (provisions exactly what's needed)
- Faster provisioning
- Better resource fit

**Key Differences from Cluster Autoscaler:**
- **Cluster Autoscaler:** Works with predefined node groups
- **Karpenter:** Provisions any node type that fits
- **Faster:** Sub-minute node provisioning
- **Smarter:** Better bin-packing and resource utilization

### Why Do We Need Karpenter?

**The Problem with Cluster Autoscaler:**
- Works with fixed node groups
- Limited node type selection
- Slower provisioning (minutes)
- Less efficient resource utilization
- Can't mix instance types easily

**The Solution - Karpenter:**
- Provisions any suitable node type
- Faster provisioning (seconds)
- Better resource utilization
- Intelligent bin-packing
- Cost optimization

### How Karpenter Works

**Karpenter Workflow:**
```
1. Pod can't be scheduled (pending)
   ‚Üì
2. Karpenter analyzes Pod requirements
   ‚Üì
3. Finds best node type(s) for the workload
   ‚Üì
4. Provisions node(s) directly (no node groups)
   ‚Üì
5. Pod gets scheduled on new node
   ‚Üì
6. Monitors node utilization
   ‚Üì
7. Consolidates/removes underutilized nodes
```

**Key Features:**
- **Direct Provisioning:** Provisions nodes directly, not through node groups
- **Multi-Instance Support:** Can mix instance types
- **Fast Provisioning:** Sub-minute node provisioning
- **Consolidation:** Automatically consolidates workloads for efficiency
- **Cost Optimization:** Chooses cost-effective instance types

### Karpenter Architecture Diagram

```mermaid
graph TB
    subgraph "Kubernetes Cluster"
        Scheduler[Scheduler<br/>Pod Scheduling]
        Pending[Pending Pods<br/>Can't Schedule]
    end
    
    subgraph "Karpenter Components"
        KarpenterCtrl[Karpenter Controller<br/>Main Controller]
        Analyzer[Workload Analyzer<br/>Requirements]
        Provisioner[Provisioner<br/>Node Provisioning]
        Consolidator[Consolidator<br/>Node Optimization]
    end
    
    subgraph "Cloud Provider API"
        EC2[EC2 API<br/>AWS]
        GCE[GCE API<br/>GCP]
        Azure[Azure API<br/>Azure]
    end
    
    subgraph "Provisioned Nodes"
        Node1[Node 1<br/>Instance Type A]
        Node2[Node 2<br/>Instance Type B]
        Node3[Node 3<br/>Instance Type C]
    end
    
    Pending --> KarpenterCtrl
    Scheduler --> KarpenterCtrl
    KarpenterCtrl --> Analyzer
    Analyzer --> Provisioner
    Provisioner --> EC2
    Provisioner --> GCE
    Provisioner --> Azure
    EC2 --> Node1
    GCE --> Node2
    Azure --> Node3
    KarpenterCtrl --> Consolidator
    Consolidator --> Node1
    
    style KarpenterCtrl fill:#326ce5,color:#fff
    style Provisioner fill:#00d4aa,color:#fff
    style Node1 fill:#f4a261,color:#000
```

### Karpenter Provisioner

**Provisioner** is a Karpenter CRD that defines how nodes should be provisioned.

**Basic Provisioner YAML:**
```yaml
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: default
spec:
  template:
    metadata:
      labels:
        intent: apps
    spec:
      nodeClassRef:
        name: default
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: kubernetes.io/os
          operator: In
          values: ["linux"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values: ["m5.large", "m5.xlarge", "m5.2xlarge"]
  limits:
    cpu: "1000"
    memory: 1000Gi
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 30s
```

**Key Fields Explained:**

**1. template:**
- **metadata.labels:** Labels applied to provisioned nodes
- **spec.nodeClassRef:** Reference to EC2NodeClass (AWS) or similar
- **spec.requirements:** Node selection requirements

**2. requirements:**
- **key:** Node selector key (arch, os, instance-type, etc.)
- **operator:** In, NotIn, Exists, etc.
- **values:** Allowed values

**3. limits:**
- **cpu:** Maximum CPU across all nodes
- **memory:** Maximum memory across all nodes

**4. disruption:**
- **consolidationPolicy:** WhenEmpty, WhenUnderutilized
- **consolidateAfter:** Time before consolidation

### EC2NodeClass (AWS)

**EC2NodeClass** defines EC2-specific configuration for Karpenter.

**Example EC2NodeClass:**
```yaml
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2
  role: KarpenterNodeRole
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: <cluster-name>
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: <cluster-name>
  tags:
    Environment: production
    ManagedBy: Karpenter
```

**Key Fields:**
- **amiFamily:** AMI family (AL2, Bottlerocket, Ubuntu)
- **role:** IAM role for nodes
- **subnetSelectorTerms:** Subnet selection
- **securityGroupSelectorTerms:** Security group selection
- **tags:** Tags applied to nodes

### Karpenter Installation

**Prerequisites:**
- Kubernetes cluster (EKS, GKE, AKS, or self-managed)
- IAM roles and permissions (for cloud provider)
- Node requirements configured

**Installation Steps (AWS EKS):**
```bash
# 1. Create IAM roles and policies
# 2. Install Karpenter
helm repo add karpenter oci://public.ecr.aws/karpenter
helm repo update
helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
  --namespace karpenter \
  --create-namespace \
  --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=<KarpenterRoleArn> \
  --set settings.clusterName=<cluster-name> \
  --set settings.defaultInstanceProfile=<InstanceProfile> \
  --wait

# 3. Create NodePool
kubectl apply -f nodepool.yaml

# 4. Create EC2NodeClass (AWS)
kubectl apply -f ec2nodeclass.yaml
```

### Karpenter vs Cluster Autoscaler

| Feature | Cluster Autoscaler | Karpenter |
|---------|-------------------|-----------|
| **Node Groups** | Required (predefined) | Not required |
| **Node Types** | Limited to node group types | Any suitable type |
| **Provisioning Speed** | Minutes | Seconds (sub-minute) |
| **Resource Utilization** | Good | Excellent (bin-packing) |
| **Instance Mixing** | Limited | Full support |
| **Consolidation** | Basic | Advanced |
| **Cost Optimization** | Good | Better |
| **Complexity** | Lower | Higher |
| **Maturity** | Very mature | Newer (growing) |

### Karpenter Best Practices

**1. Configure Appropriate Limits:**
- Set CPU and memory limits
- Prevent runaway provisioning
- Control costs

**2. Use Spot Instances:**
- Configure spot instance support
- Significant cost savings
- Handle interruptions gracefully

**3. Set Consolidation Policy:**
- Use WhenUnderutilized for cost savings
- Use WhenEmpty for faster consolidation
- Balance between cost and stability

**4. Configure Requirements:**
- Specify instance types
- Set capacity type preferences
- Define architecture requirements

**5. Use Multiple NodePools:**
- Different NodePools for different workloads
- GPU nodes, compute-optimized, etc.
- Workload-specific optimization

**6. Monitor Karpenter:**
- Watch provisioning events
- Monitor consolidation
- Check node utilization
- Review costs

**7. Test Provisioning:**
- Test scale-up scenarios
- Test consolidation
- Verify instance selection

### Karpenter Limitations

**1. Cloud Provider Support:**
- Best support for AWS (EKS)
- GCP and Azure support available
- On-premises support limited

**2. Learning Curve:**
- Newer technology
- Different concepts than Cluster Autoscaler
- Requires understanding of Provisioners

**3. Stateful Workloads:**
- Consolidation can disrupt workloads
- Configure disruption budgets
- Use appropriate consolidation policies

**4. Cost Management:**
- Can provision many nodes quickly
- Set appropriate limits
- Monitor provisioning closely

### Key Takeaways

1. **Karpenter is a modern autoscaler** - Faster and more efficient than Cluster Autoscaler
2. **Direct node provisioning** - No node groups required
3. **Fast provisioning** - Sub-minute node provisioning
4. **Better resource utilization** - Intelligent bin-packing
5. **Cost optimization** - Chooses cost-effective instances
6. **Consolidation** - Automatically optimizes node usage
7. **Requires configuration** - NodePools and node classes needed
8. **Best for AWS** - Excellent EKS support

---

### Autoscaling Comparison

| Feature | HPA | VPA | KEDA | Cluster Autoscaler | Karpenter |
|---------|-----|-----|------|-------------------|-----------|
| **What It Scales** | Pods | Resources | Pods | Nodes | Nodes |
| **Based On** | CPU/Memory metrics | Historical usage | External events | Scheduling needs | Scheduling needs |
| **Scale Direction** | Horizontal | Vertical | Horizontal | Infrastructure | Infrastructure |
| **Scale to Zero** | No (min: 1) | N/A | Yes | No | No |
| **Use Case** | Web services | Resource optimization | Event-driven | Cluster capacity | Cluster capacity |
| **Complexity** | Low | Medium | High | High | High |
| **Standard K8s** | Yes | No | No | No | No |
| **Node Groups** | N/A | N/A | N/A | Required | Not required |
| **Provisioning Speed** | N/A | N/A | N/A | Minutes | Seconds |
| **Resource Fit** | N/A | N/A | N/A | Good | Excellent |

### Combining Autoscalers

**Common Combinations:**
1. **HPA + Cluster Autoscaler/Karpenter:**
   - HPA scales Pods
   - Cluster Autoscaler/Karpenter adds nodes when needed
   - Most common combination

2. **KEDA + Cluster Autoscaler/Karpenter:**
   - KEDA scales based on events
   - Cluster Autoscaler/Karpenter adds nodes for event processing
   - For event-driven workloads

3. **VPA (Initial) + HPA:**
   - VPA optimizes resources
   - HPA scales Pod count
   - Use different metrics

4. **HPA + Karpenter:**
   - HPA scales Pods horizontally
   - Karpenter provisions optimal nodes
   - Best for AWS EKS with fast scaling needs

**Don't Combine:**
- VPA (Auto) + HPA (CPU/Memory) - Can conflict
- Multiple HPAs on same resource - Use one HPA
- Cluster Autoscaler + Karpenter - Choose one node autoscaler

### Key Takeaways

1. **Autoscaling optimizes resources** - Automatically adjusts to demand
2. **Multiple autoscalers available** - Choose based on needs
3. **HPA for horizontal scaling** - Most common for Pod scaling
4. **VPA for resource optimization** - Adjusts CPU/memory per Pod
5. **KEDA for event-driven scaling** - Based on external events
6. **Cluster Autoscaler for infrastructure** - Traditional node autoscaler
7. **Karpenter for modern infrastructure** - Fast, efficient node autoscaler
8. **Can combine autoscalers** - Use multiple together carefully
9. **Monitor and test** - Ensure autoscaling works as expected

Autoscaling is essential for running efficient, cost-effective Kubernetes clusters. Choose the right autoscaler(s) based on your workload characteristics and requirements.

</details>

---

<details>
<summary><h2>Taints and Tolerations</h2></summary>

## Taints and Tolerations

**Taints and Tolerations** are mechanisms in Kubernetes that allow you to mark nodes (taints) and allow pods to be scheduled on those nodes (tolerations). They work together to control which pods can be scheduled on which nodes.
